# 工作日志
2023.7.6-2023.7.13 高朗

## 本周主要完成的工作
- 在服务器端部署了没有微调的模型chatglm2-6B.
- 设计了prompt使模型将结果返回为json格式并且写入文件`resp.json`中。
- 针对原始数据集中的1029条语料数据进行了准确率的计算（假设数据集是正确的）
## 实验结果
计算方法：语病判断准确率：计算合并后的文件中，同一条记录里语病类型的判断是否一致。
校正后病句与原正确句子的一致性：同一条记录里修改后句子与原句的一致性。
- 语病判断准确率：0.044487427466150864
- 校正后病句与原正确句子的一致性统计：0
## 实验结果分析
- 数据集存在问题：数据集存在长度很高的单句，包含语病很细微不容易发现；同时有些生成的病句其实也不存在明显语病；有些生成的病句直接导致了语言混乱，丧失了原有的句意。这些都导致模型很难做到修改结果跟数据集完全一致。
- 模型存在问题：将json转化csv文件后与数据集文件基于“病句”标签进行左连接，结果发现出现很多空值。这可能意味着模型在生成回答的时候对问题的复述存在自行修改的情况。
## 后期工作
- 数据集优化：可能需要人力手工校对数据，当前数据集包含200000条病句，很大一部分不能用。
- prompt优化：根据chatglm2-6B的应答特征设计更稳定的prompt。
- 基于规则的病句生成算法优化：事实证明CLG-CGEC距离快速生成高质量病句的能力还有待提升，可以在长期对其优化进行一定的研究和尝试。
- 模型的微调：数据集优化之后尝试使用p-tuning对模型微调（因为HF提供了微调的接口）。